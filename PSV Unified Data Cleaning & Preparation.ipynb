{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a23c500-e355-49d5-abf0-b26225799484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python# coding: utf-8\n",
    "# ==========================================\n",
    "# ğŸ“˜ PSV Unified Data Cleaning & Preparation\n",
    "# ==========================================\n",
    "# Author: Georgi\n",
    "# Description:\n",
    "# - Cleans and standardizes PSV-related CSV datasets\n",
    "# - Auto-detects and fixes nested JSON/list fields\n",
    "# - Converts percentage and count fields to numeric\n",
    "# - Handles both structured & unstructured data\n",
    "# - Correctly parses semicolon-delimited text with quotes\n",
    "# - Outputs all cleaned CSVs into /cleaned_final/\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import csv\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f8c670c-1115-494d-b7d7-b07bf2614778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Please select the folder containing your PSV CSV files...\n",
      "âœ… Selected folder: C:/Users/georg/Downloads/testings/working_files_to_cleaned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Setup\n",
    "# -----------------------------\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Ask user to select folder with CSVs\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the small tkinter window\n",
    "\n",
    "print(\"ğŸ“‚ Please select the folder containing your PSV CSV files...\")\n",
    "data_folder = filedialog.askdirectory(title=\"Select Folder with PSV CSV Files\")\n",
    "\n",
    "if not data_folder:\n",
    "    raise SystemExit(\"âŒ No folder selected. Exiting notebook.\")\n",
    "\n",
    "print(f\"âœ… Selected folder: {data_folder}\\n\")\n",
    "\n",
    "# Create output folder in same directory\n",
    "output_folder = os.path.join(data_folder, \"cleaned_final\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "datasets = {\n",
    "    \"transfermarket\": {\"file\": \"Transfermarket.csv\", \"sep\": \",\"},\n",
    "    \"competitor_profiles\": {\"file\": \"combined_competitor_profiles.csv\", \"sep\": \",\"},\n",
    "    \"news_topics\": {\"file\": \"news_topics-sentiment-actions.csv\", \"sep\": \",\"},\n",
    "    \"socials_topics\": {\"file\": \"socials_topics-sentiment-actions.csv\", \"sep\": \",\"},\n",
    "    \"socials_overview\": {\"file\": \"socials-posts-overview.csv\", \"sep\": \",\"},\n",
    "    \"google_headlines\": {\"file\": \"Google_headlines.csv\", \"sep\": \";\"},\n",
    "    \"eventregistry_headlines\": {\"file\": \"Eventregistry_headlines.csv\", \"sep\": \",\"},\n",
    "    \"facebook_comments\": {\"file\": \"facebook-comments.csv\", \"sep\": \",\"},\n",
    "    \"facebook_competitors\": {\"file\": \"facebook-competitor-profiles.csv\", \"sep\": \";\"},\n",
    "    \"facebook_posts\": {\"file\": \"facebook-posts_overview.csv\", \"sep\": \",\"},\n",
    "    \"instagram_comments\": {\"file\": \"instagram-comments.csv\", \"sep\": \",\"},\n",
    "    \"instagram_posts\": {\"file\": \"instagram-posts_overview.csv\", \"sep\": \",\"},\n",
    "    \"tiktok_comments\": {\"file\": \"tiktok-comments.csv\", \"sep\": \",\"},\n",
    "    \"tiktok_posts\": {\"file\": \"tiktok-posts_overview.csv\", \"sep\": \",\"},\n",
    "    \"youtube_comments\": {\"file\": \"youtube-comments.csv\", \"sep\": \";\"},\n",
    "    \"youtube_posts\": {\"file\": \"youtube-posts.csv\", \"sep\": \";\"},\n",
    "    \"youtube_overview\": {\"file\": \"youtube-posts-overview.csv\", \"sep\": \";\"},\n",
    "    \"youtube_competitors\": {\"file\": \"youtube-competitor-profiles.csv\", \"sep\": \";\"},\n",
    "    \"tiktok_competitors\": {\"file\": \"tiktok-competitor-profiles.csv\", \"sep\": \";\"},\n",
    "    \"instagram_competitors\": {\"file\": \"instagram-competitor-profiles.csv\", \"sep\": \";\"},\n",
    "    \"twitter_competitors\": {\"file\": \"twitter-competitor-profiles.csv\", \"sep\": \";\"},\n",
    "    \"psv_matches\": {\"file\": \"psv_matches_season_25_26.csv\", \"sep\": \",\"},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815d6663-9f16-4ddc-89da-b3c04a5642e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generic cleanup for all datasets.\"\"\"\n",
    "    df.dropna(how=\"all\", inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .replace({\"not available\": np.nan, \"N/A\": np.nan, \"\": np.nan})\n",
    "        )\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def try_parse_json(value):\n",
    "    \"\"\"Safely parse JSON-like text fields.\"\"\"\n",
    "    if not isinstance(value, str):\n",
    "        return value\n",
    "    value = value.strip()\n",
    "    if value in [\"\", \"nan\", \"None\"]:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return json.loads(value)\n",
    "    except:\n",
    "        try:\n",
    "            return literal_eval(value)\n",
    "        except:\n",
    "            return value\n",
    "\n",
    "def convert_numeric(df: pd.DataFrame):\n",
    "    \"\"\"Convert percentage and numeric count columns.\"\"\"\n",
    "    for col in df.columns:\n",
    "        if \"%\" in col or \"rate\" in col or \"count\" in col or \"score\" in col:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
    "    return df\n",
    "\n",
    "def load_and_clean_csv(file_path: str, sep: str, dataset_name: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        # Add quote handling for tricky files\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            sep=sep,\n",
    "            engine=\"c\",\n",
    "            on_bad_lines=\"skip\",\n",
    "            dtype=str,\n",
    "            low_memory=False,\n",
    "            quoting=csv.QUOTE_MINIMAL,\n",
    "        )\n",
    "\n",
    "        df = clean_dataframe(df)\n",
    "\n",
    "        # Dataset-specific logic\n",
    "        # --------------------------------\n",
    "\n",
    "        # Competitor normalization\n",
    "        if \"competitor_profiles\" in dataset_name and \"club\" in df.columns:\n",
    "            df[\"club\"] = df[\"club\"].str.upper().str.strip()\n",
    "            club_replacements = {\n",
    "                \"FEYENOORD ROTTERDAM\": \"FEYENOORD\",\n",
    "                \"PSV EINDHOVEN\": \"PSV\",\n",
    "                \"AJAX AMSTERDAM\": \"AJAX\",\n",
    "                \"AZ ALKMAAR\": \"AZ\",\n",
    "                \"FC TWENTE ENSCHEDE\": \"FC TWENTE\",\n",
    "            }\n",
    "            df[\"club\"] = df[\"club\"].replace(club_replacements)\n",
    "            if {\"followers\", \"source\"}.issubset(df.columns):\n",
    "                df = df.groupby([\"club\", \"source\"], as_index=False)[\"followers\"].sum()\n",
    "\n",
    "        # Twitter competitor posts (already structured JSON)\n",
    "        elif \"twitter_competitors\" in dataset_name:\n",
    "            all_posts = []\n",
    "            for _, row in df.iterrows():\n",
    "                posts_raw = row.get(\"posts\", None)\n",
    "                if not posts_raw or posts_raw.strip() == \"\" or posts_raw == \"[]\":\n",
    "                    continue\n",
    "                try:\n",
    "                    posts_list = json.loads(posts_raw)\n",
    "                except:\n",
    "                    try:\n",
    "                        posts_list = literal_eval(posts_raw)\n",
    "                    except:\n",
    "                        continue\n",
    "                for post in posts_list:\n",
    "                    all_posts.append(\n",
    "                        {\n",
    "                            \"profile_id\": row.get(\"id\"),\n",
    "                            \"profile_name\": row.get(\"profile_name\"),\n",
    "                            \"followers\": row.get(\"followers\"),\n",
    "                            \"post_id\": post.get(\"post_id\"),\n",
    "                            \"description\": post.get(\"description\"),\n",
    "                            \"date_posted\": post.get(\"date_posted\"),\n",
    "                            \"likes\": post.get(\"likes\"),\n",
    "                            \"views\": post.get(\"views\"),\n",
    "                            \"reposts\": post.get(\"reposts\"),\n",
    "                            \"replies\": post.get(\"replies\"),\n",
    "                            \"hashtags\": post.get(\"hashtags\"),\n",
    "                        }\n",
    "                    )\n",
    "            df = pd.DataFrame(all_posts)\n",
    "\n",
    "        # Instagram competitor posts (JSON-like structure)\n",
    "        elif \"instagram_competitors\" in dataset_name and \"posts\" in df.columns:\n",
    "            all_posts = []\n",
    "            for _, row in df.iterrows():\n",
    "                posts_raw = row[\"posts\"]\n",
    "                if pd.isna(posts_raw) or posts_raw.strip() == \"\":\n",
    "                    continue\n",
    "                posts_list = try_parse_json(posts_raw)\n",
    "                if not isinstance(posts_list, list):\n",
    "                    continue\n",
    "                for post in posts_list:\n",
    "                    all_posts.append(\n",
    "                        {\n",
    "                            \"account\": row.get(\"account\"),\n",
    "                            \"followers\": row.get(\"followers\"),\n",
    "                            \"post_id\": post.get(\"id\"),\n",
    "                            \"caption\": post.get(\"caption\"),\n",
    "                            \"likes\": post.get(\"likes\"),\n",
    "                            \"comments\": post.get(\"comments\"),\n",
    "                            \"date_posted\": post.get(\"date_posted\"),\n",
    "                            \"hashtags\": post.get(\"hashtags\"),\n",
    "                        }\n",
    "                    )\n",
    "            if all_posts:\n",
    "                df = pd.DataFrame(all_posts)\n",
    "\n",
    "        # TikTok competitor profiles (parse top_videos, top_posts_data)\n",
    "        elif \"tiktok_competitors\" in dataset_name:\n",
    "            for field in [\"top_videos\", \"top_posts_data\", \"discovery_input\"]:\n",
    "                if field in df.columns:\n",
    "                    df[field] = df[field].apply(try_parse_json)\n",
    "\n",
    "        # Posts overview (hashtags list parsing)\n",
    "        elif \"posts_overview\" in dataset_name and \"hashtags\" in df.columns:\n",
    "            df[\"hashtags\"] = df[\"hashtags\"].apply(try_parse_json)\n",
    "\n",
    "        # Sentiment-based datasets (convert % to floats)\n",
    "        elif \"news_topics\" in dataset_name or \"socials_topics\" in dataset_name:\n",
    "            df = convert_numeric(df)\n",
    "\n",
    "        # Facebook competitor quote issues handled via quoting above\n",
    "\n",
    "        # Convert all numeric fields possible\n",
    "        df = convert_numeric(df)\n",
    "\n",
    "        # Fill missing columns and clean\n",
    "        df = df.reindex(columns=sorted(df.columns))\n",
    "        df = df.replace(\"nan\", np.nan)\n",
    "\n",
    "        print(f\"âœ… {dataset_name}: {len(df)} rows, {len(df.columns)} cols cleaned successfully.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {dataset_name} failed: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f962a9bc-0830-44c1-b95b-bbefd089e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… transfermarket: 17 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\transfermarket_cleaned.csv\n",
      "\n",
      "âœ… competitor_profiles: 15 rows, 3 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\competitor_profiles_cleaned.csv\n",
      "\n",
      "âœ… news_topics: 423 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\news_topics_cleaned.csv\n",
      "\n",
      "âœ… socials_topics: 2081 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\socials_topics_cleaned.csv\n",
      "\n",
      "âœ… socials_overview: 233 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\socials_overview_cleaned.csv\n",
      "\n",
      "âœ… google_headlines: 212 rows, 5 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\google_headlines_cleaned.csv\n",
      "\n",
      "âœ… eventregistry_headlines: 211 rows, 7 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\eventregistry_headlines_cleaned.csv\n",
      "\n",
      "âœ… facebook_comments: 628 rows, 11 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\facebook_comments_cleaned.csv\n",
      "\n",
      "âœ… facebook_competitors: 3 rows, 16 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\facebook_competitors_cleaned.csv\n",
      "\n",
      "âœ… facebook_posts: 20 rows, 15 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\facebook_posts_cleaned.csv\n",
      "\n",
      "âœ… instagram_comments: 1473 rows, 6 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\instagram_comments_cleaned.csv\n",
      "\n",
      "âœ… instagram_posts: 200 rows, 11 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\instagram_posts_cleaned.csv\n",
      "\n",
      "âœ… tiktok_comments: 76 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\tiktok_comments_cleaned.csv\n",
      "\n",
      "âœ… tiktok_posts: 9 rows, 15 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\tiktok_posts_cleaned.csv\n",
      "\n",
      "âœ… youtube_comments: 40 rows, 10 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\youtube_comments_cleaned.csv\n",
      "\n",
      "âœ… youtube_posts: 4 rows, 19 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\youtube_posts_cleaned.csv\n",
      "\n",
      "âœ… youtube_overview: 4 rows, 19 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\youtube_overview_cleaned.csv\n",
      "\n",
      "âœ… youtube_competitors: 3 rows, 9 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\youtube_competitors_cleaned.csv\n",
      "\n",
      "âœ… tiktok_competitors: 3 rows, 24 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\tiktok_competitors_cleaned.csv\n",
      "\n",
      "âœ… instagram_competitors: 36 rows, 8 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\instagram_competitors_cleaned.csv\n",
      "\n",
      "âœ… twitter_competitors: 215 rows, 11 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\twitter_competitors_cleaned.csv\n",
      "\n",
      "âœ… psv_matches: 36 rows, 7 cols cleaned successfully.\n",
      "ğŸ’¾ Saved â†’ C:/Users/georg/Downloads/testings/working_files_to_cleaned\\cleaned_final\\psv_matches_cleaned.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Process all datasets\n",
    "# -----------------------------\n",
    "cleaned_dataframes = {}\n",
    "\n",
    "for name, meta in datasets.items():\n",
    "\n",
    "    sep = meta[\"sep\"]\n",
    "    path = os.path.join(data_folder, meta[\"file\"])\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"âš ï¸ Missing file: {path}\")\n",
    "        continue\n",
    "\n",
    "    cleaned_df = load_and_clean_csv(path, sep, name)\n",
    "    cleaned_dataframes[name] = cleaned_df\n",
    "\n",
    "    out_path = os.path.join(output_folder, f\"{name}_cleaned.csv\")\n",
    "    cleaned_df.to_csv(out_path, index=False)\n",
    "    print(f\"ğŸ’¾ Saved â†’ {out_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fca2a90-d2b3-408b-9322-e57b40cdd448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ All PSV datasets cleaned successfully!\n",
      "ğŸ“¦ Total datasets cleaned: 22\n",
      "ğŸ“ Output folder: cleaned_final/\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "print(\"ğŸ¯ All PSV datasets cleaned successfully!\")\n",
    "print(f\"ğŸ“¦ Total datasets cleaned: {len(cleaned_dataframes)}\")\n",
    "print(\"ğŸ“ Output folder: cleaned_final/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3f85e-950f-480c-93ed-68c320d0d263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
